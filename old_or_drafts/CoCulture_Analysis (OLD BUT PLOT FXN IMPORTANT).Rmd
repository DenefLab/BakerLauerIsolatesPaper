---
title: "CoCulture_Analysis"
author: "James Lauer"
date: "10/6/2021"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(eval = TRUE,
                      echo = TRUE,
                      cache = TRUE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      warning = FALSE,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE)

library(tidyverse)
library(lubridate)
library(lme4)
library(parallel)
library(foreach)
library(doParallel)
library(DescTools)
library(broom)

numCores <- detectCores()
registerDoParallel(numCores)
```

## Analysis Screening Coculture Experiments

Uses the packages tidyverse, lubridate, lme4, parallel, foreach, and doParallel

CPU cores calculated for use in the parallel, foreach, and doParallel packages.

### Important Paths
These paths may be edited or changed to facilitate smoother or more organized plot saves. The folder_list outlines the paths to raw data.
```{r Important Paths}
path_plots <- "./CoCulture_figures/isolate_plots"

path_dot_plots <- paste(path_plots, "dot_plots", sep = "/")

path_mean_plots <- paste(path_plots, "mean_plots", sep = "/")

folder_list <- list.dirs(path = "./CoCulture_Data", full.names = TRUE, recursive = FALSE) %>%
  ifelse(str_detect(. , pattern = regex("plate_(\\d|\\d\\d)_(chlorella|coelastrum|scenedesmus|monoraphidium|selenastrum)$", ignore_case = TRUE)), .,NA) %>%
  na.omit()
```

### Functions
All functions used in this analysis.

#### Data Processing
Data processing functions are used to pull raw data into R, rename columns for ease of use, and calculate the time in hours between read times in datetime format. 
```{r Data Processing Functions}
read_plate <- function(plate_list) {
  read_csv(plate_list,
           col_types = cols(.default = col_double(),
                            Well = col_character(),
                            `Well ID` = col_character(),
                            # Format no longer an issue
                            `Reading Date/Time` = col_datetime(format = "%Y-%m-%d %H:%M:%S"))) %>%
    rename(ChlA_100 = `Mean RFU [ChlA_100:460,685]`, 
           read_time = `Reading Date/Time`)%>%
    #Extract plate information and species from each file to aid in isolate mapping.
    mutate(plate_no = str_extract(str_extract(plate_list, pattern = "Plate_(\\d\\d|\\d)"),pattern = regex("(\\d\\d|\\d)")), 
           host_species = str_extract(plate_list, pattern = "(chlorella|coelastrum|scenedesmus|monoraphidium|selenastrum)"),
           filename = plate_list,
           read_day = str_extract(str_extract(plate_list, pattern = "(\\d\\d|\\d).csv"), pattern = regex("(\\d\\d|\\d)"))) %>%
    select(Well, ChlA_100, read_time, read_day, plate_no, host_species)
}

read_map <- function(map_list) {
  read_csv(map_list, col_types = cols(.default = col_character())) %>%
    mutate(Isolate = as.character(Isolate),
           plate_no = str_extract(str_extract(map_list, pattern = "Plate_(\\d\\d|\\d)"),pattern = regex("(\\d\\d|\\d)")), 
           host_species = str_extract(map_list, pattern = "(chlorella|coelastrum|scenedesmus|monoraphidium|selenastrum)"),
           filename = map_list) %>%
    select(-filename)
}

calc_time <- function(df){
  data <- df%>%
    mutate(exact_isolate = paste("Plate", plate_no, Isolate, Well, sep = "_"))
  day_0 <- data %>%
    arrange(read_day)%>% 
    distinct(exact_isolate, .keep_all = TRUE)%>%
    mutate(begin = read_time) %>%
    select(exact_isolate, begin)
  data_with_time <- left_join(data, day_0)%>%
    mutate(read_interval = begin %--% read_time,
           read_timeHours = as.numeric(as.duration(read_interval)/dhours(1)))%>%
    select(-begin, -read_interval)
  return(data_with_time)
}

flag_outlier <- function(df){
  data <- df %>%
    group_by(plate_no, Isolate, read_day)%>%
    mutate(day_mean = mean(ChlA_100, na.rm=TRUE),
           day_sd = sd(ChlA_100, na.rm=TRUE))%>%
    ungroup()%>%
    mutate(Outlier = ifelse((day_mean-(2*day_sd))>ChlA_100|(day_mean+(2*day_sd))<ChlA_100, TRUE, FALSE))
  return(data)
}

day_Isolated <- function(df){
  data <- df%>%
    mutate(Day_isolated = ifelse(str_detect(Isolate, "D3")==TRUE, "D3", ifelse(str_detect(Isolate, "DF")==TRUE, "D31", "Ctrl")))
  return(data)
}

flag_algae <- function(df){
  data_raw <- df
  AC_day0_avg <- df %>%
    filter(Isolate == "AC" & read_day == 0)%>%
    summarize(ChlA_100_mean = mean(ChlA_100))%>%
    as.numeric()
  data_flagged <- df %>%
    filter(read_day == 0)%>%
    mutate(algae_flag = ifelse(ChlA_100 > 2*AC_day0_avg, TRUE, FALSE))%>%
    select(Isolate, algae_flag)%>%
    distinct()%>%
    left_join(data_raw, .)
  return(data_flagged)
}
```

#### Statistics Functions
Statistics functions are used to fit linear and linear mixed effects models to datasets composed of Chlorophyl A Fluorescence measurements of xenic algal-bacterial coculture samples and axenic algal controls of the same species. The linear model does not consider the presence of a bacterial isolate, and illustrates the null hypothesis: the presence of a bacterial isolate has no impact on algal growth. The linear mixed effects model considers the presence of a bacterial isolate as a random effect, thereby illustrating the alternative hypothesis: the presence of a bacterial isolate significantly alters algal growth. These two models are then compared using a Likelihood Ratio Test (LRT or Wilks Test) to calculate an initial P-value. A parametric bootstrap approach is then employed to achieve greater accuracy. We begin by estimating the probability of achieving the observed LRT result given the null hypothesis is true. To do this, 1000 simulations are conducted under the null hypothesis, data from each is fitted with both the null and alternative model, then the LRT is calculated. The proportion of LRTs generated from the simulation data exceeding the observed LRT calculated from the experimental dataset is used to estimate the true P-value.
```{r Statistics Functions}
reg_test <- function(df){
  data <- df
  modData <- data %>% select(Isolate, read_timeHours, ChlA_100)
  null.mod <- lm(ChlA_100 ~ 1 + read_timeHours, modData)
  alt.mod <- lmer(ChlA_100 ~ 1 + read_timeHours + (1|Isolate), modData)
  lrt <- as.numeric(2*(logLik(alt.mod) - logLik(null.mod)))
  lrt
  pChi <- pchisq(lrt, 1, lower = FALSE)
  
  y <- simulate(null.mod)
  
  lrstat <- foreach(i = 1:500, .packages = "lme4", .combine = "c") %dopar% {
    y <- unlist(simulate(null.mod))
    null <- lm(y ~ 1 + read_timeHours, modData)
    alt <- lmer(y ~ 1 + read_timeHours + (1|Isolate), modData)
    lrstat <- as.numeric(2*(logLik(alt) - logLik(null)))
    return(lrstat)
    }
  mean(lrstat < 0.0001)
  pSim <- mean(lrstat > lrt)
  SEpSim <- sqrt(pSim*(1-pSim)/500)
  stats <- data%>% 
    mutate(pChi = pChi,
           pSim = pSim,
           SEpSim = SEpSim)
  return(stats)
}

calc_reg_stats <- function(n){
  pNum = n
  iData <- sampleData%>%
    filter(plate_no == pNum,
           Isolate != "55DF") # This isolate does not cooperate with the model
  iData_split <- split(iData, iData$Isolate)
  ctrl_data <- ctrlData%>%
    filter(plate_no == pNum & Isolate == "AC")
  rbind_ctrl<-function(df){
    dataframe <- rbind(ctrl_data, df)
    return(dataframe)
  }
  bound_list <- lapply(iData_split, rbind_ctrl)
  stats_models <- lapply(bound_list, reg_test)
  stats_df <- bind_rows(stats_models, .id = "Isolate") %>%
    na.omit()
  
  return(stats_df)
} 
```

#### Plotting
These functions generate plots of each algal growth curve and saves them into the folders defined in the Important Paths Section. 2 functions are included: one that plots florescence measurements for each of the three triplicate wells and includes a regression line (method = LOESS) and another that plots the mean florescence of the three wells, with error bars showing +/-1 standard deviation. (NOTE: Perhaps change this to standard error).
```{r Plotting Functions}
dot_plot_isolates <- function(c){
  isolate <- c
  isolate_data <- figData %>%
    filter(Isolate == isolate)
# Plate Number
  pnum <- as.numeric(unique(isolate_data$plate_no))
# Maximum Time
  max_time <- isolate_data %>%
    summarize(xlim = max(read_timeHours))
  xlim <- as.numeric(unique(max_time$xlim)) + 20
# getting title
  isolate_species <- isolate_data %>%
    mutate(plot_title = paste(Isolate, "Grown with", host_species, sep = " "))
  plot_title <- as.character(unique(isolate_species$plot_title))
# Annotation Text
  annotation <- unique(isolate_data$annotation)
# AC data
  AC_data <- ctrlData %>%
    filter(plate_no == pnum & Isolate == "AC")
# MC data
  MC_data <- ctrlData %>%
    filter(plate_no == pnum & Isolate == "MC")
# plot starts here
  plot <- ggplot(data = isolate_data,
                 aes(x = read_timeHours, y = ChlA_100, color = Effect))+
    geom_point(data = AC_data,
               color = "black",
               aes(x = read_timeHours, y = ChlA_100))+
    geom_point(data = MC_data,
               color = "gray",
               aes(x = read_timeHours, y = ChlA_100))+
    geom_point()+
    coord_cartesian(xlim = c(0, xlim), ylim = c(0, 800))+
    labs(x="Time (hours)",
         y="Chlorophyll A Fluorescence (RFU)",
         title = plot_title)+
    annotate("text", x = xlim - 25, y = 700, label = annotation)+
    scale_color_manual(name = "Effect Observed",
                       values = c("Not Significant" = "gray",
                                  "No Change to AUC" = "green2",
                                  "Positive" = "cornflowerblue",
                                  "Negative" = "orange"),
                     guide = guide_legend(reverse = TRUE))+
    theme_light()
# save starts here
  file_name <- paste("plate", pnum, plot_title, sep = '_')%>%
    paste(., "png", sep=".")
  ggsave(file_name, plot = plot, device = "png",
         path = path_dot_plots, scale = 1, width = 4.5, height = 4,
         dpi = 300, units = "in", limitsize = TRUE)
  return(plot)
}

### If Regression Lines (method LOESS) Desired, insert this code chunk into dot plot function:
# geom_smooth(data = AC_data,
#             color = "black",
#             alpha = 0,
#             size = .5,
#             aes(x = read_timeHours, y = ChlA_100))+
# geom_smooth(data = MC_data,
#             color = "gray",
#             alpha = 0,
#             size = .5,
#             aes(x = read_timeHours, y = ChlA_100))+
# geom_smooth(alpha = 0,
#             size = .5,)+


 mean_plot_isolates <- function(chr){
  isolate <- chr
  isolate_data <- dataMean %>%
    filter(Isolate == isolate)
  # Plate number
  pnum <- as.numeric(unique(isolate_data$plate_no))
  #  maximum x value
  xlim <- isolate_data %>%
    summarize(xlim = max(read_timeHours))%>%
    as.numeric() + 20
  # plot title
  plot_title <- isolate_data %>%
    mutate(plot_title = paste(Isolate, host_species, sep = "_"))%>%
    select(plot_title)%>%
    distinct()%>%
    as.character()
  # Significance Annotation
  annotation <- unique(isolate_data$annotation)
  # AC data
  AC_data <- dataMean %>%
    filter(plate_no == pnum & Isolate == "AC")
  # MC data
  MC_data <- dataMean %>%
    filter(plate_no == pnum & Isolate == "MC")
  # actually plotting now
  plot <- ggplot(data = isolate_data,
                 aes(x = read_timeHours, y = ChlA_100_mean))+
    geom_line(data = AC_data,
              color = "black", 
              aes(x = read_timeHours, y = ChlA_100_mean))+
    geom_point(data = AC_data,
               color = "black", 
               aes(x = read_timeHours, y = ChlA_100_mean))+
    geom_errorbar(data = AC_data,
                  color = "black",
                  width = .2,
                  aes(ymin = ChlA_100_mean - ChlA_100_sd, 
                      ymax = ChlA_100_mean + ChlA_100_sd))+
    geom_line(data = MC_data, 
              color = "gray", 
              aes(x = read_timeHours, y = ChlA_100_mean))+
    geom_point(data = MC_data,
               color = "gray", 
               aes(x = read_timeHours, y = ChlA_100_mean))+
    geom_errorbar(data = MC_data,
                  color = "gray",
                  width = .2,
                  aes(ymin = ChlA_100_mean - ChlA_100_sd, 
                      ymax = ChlA_100_mean + ChlA_100_sd))+
    geom_line(color = "green2")+
    geom_point(color = "green2")+
    geom_errorbar(color = "green2",
                  width = .2,
                  aes(ymin = ChlA_100_mean - ChlA_100_sd, 
                      ymax = ChlA_100_mean + ChlA_100_sd))+
    coord_cartesian(xlim = c(0, xlim), ylim = c(0, 800))+
    labs(x="Time (hours)", 
         y="Chlorophyll A Fluorescence (RFU)", 
         title = plot_title)+
    annotate("text", x = xlim - 25, y = 700, label = annotation)+
    theme_light()
  # saving
  file_name <- paste("plate", pnum, plot_title, sep = '_')%>%
    paste(., "png", sep=".")
  ggsave(file_name, plot = plot, device = "png",
         path = path_mean_plots, scale = 1, width = 4.5, height = 4,
         dpi = 300, units = "in", limitsize = TRUE)  
  return(plot)
}
```

### Data Import
This section pulls raw data into R

#### Plate Data
The plate data import section specifically imports raw data from daily plate reader measurements. This raw data is pulled into a list and each csv (read into a dataframe) contains florescence data for all sample-containing wells of a numbered 96 well plate from a single read.
```{r Plate Data Import}
plate_list <- list.files(path = folder_list, pattern = "^Plate_(\\d\\d|\\d)_Day_(\\d\\d|\\d).csv",
                         full.names = TRUE, ignore.case = TRUE)

plate_data_all <-
  plate_list %>% 
  map_df(~read_plate(.))
```

#### Map Data
The map data section pulls in keys that define which sample is in each well of the numbered experimental plates. Only one plate map is needed for each plate, regardless of how many plate reads were conducted.
```{r Plate Map Import}
map_list <- list.files(path = folder_list, pattern = "^plate_(\\d\\d|\\d)_map.csv",
                       full.names = TRUE, ignore.case = TRUE)

map_data_all <- 
  map_list %>%
  map_df(~read_map(.))
```

### Data Processing
This section pulls together the various raw data, map, and key imports, joining them into one large dataframe called "data". Some columns/variables are renamed for clarity or ease of analysis, and the calc_time function is employed to calculate the time in hours between plate reads, which are preserved in datetime format and come directly from the plate read raw data. The data dataframe is then written to a CSV file for ease of access for any later analysis ("coculture_data.csv"). This step is optional, and can be removed if desired.
```{r Data Processing}
data <- inner_join(plate_data_all, map_data_all,
                        by = c("Well", "plate_no", "host_species"))%>%
  calc_time()%>%
  day_Isolated()%>%
  flag_outlier()%>%
  # mutate(Isolate_Plate = paste(Isolate, plate_no, sep = "_"))%>%
  select(Well, host_species, plate_no, Day_isolated, Isolate, exact_isolate, read_day, read_time, read_timeHours, ChlA_100, day_mean, day_sd, Outlier)

write.csv(data, "./CoCulture_Data/coculture_data.csv")
```

### Statistics Calculations
In this section, data is slightly reformatted for the application of the models and statistics calculations outlined above. The large dataframe "data" is separated into sample data and control data, sample data is split into a list of small dataframes so that each isolate-algae coculture combination is contained in a single dataframe, then each of these individual sample dataframes is bound to a dataframe containing data for the axenic algae control sample of the same species on the same plate. The modeling and simulation functions outlined in the Statistics Functions section are then applied to this list of dataframes.
The results of these calculations are compiled into one large dataframe (called "stats") that lists both the Wilks test p-value and the refined p-value for each sample, and includes annotations for future plots based on the siginifcance level of each P-value. This dataframe is written into a CSV file (afh_stats_new.csv) for future reference.
NOTE: The simulation portions of this section require a large amount of computational power and time. It is recommended that it be run on a fast computer or computing core if available, and are the main reasons for the inclusion of the parallel, foreach, and doParallel packages.
```{r Statistics Calculations}
sampleData <- data %>%
  filter(Day_isolated != "Ctrl")

ctrlData <- data %>%
  filter(Day_isolated == "Ctrl")

pNums <- as.list(unique(data$plate_no))

# system.time(stats_list <- mclapply(pNums, calc_reg_stats))
stats_list <- read.csv("./CoCulture_Data/coculture_stats_new.csv") %>% select(-X)%>%
  split(., .$Isolate)

stats <- bind_rows(stats_list) %>%
  mutate(SEpSim = (pSim*(1-pSim)/100),
         chiSig = ifelse(pChi <= 0.05, T, F),
         simSig = ifelse(pSim + SEpSim <= 0.05, T, F),
         simsMatch = ifelse(chiSig == simSig, T, F),
         annotation = ifelse(pChi <= 0.005, "***",
                             ifelse(pChi <= 0.01, "**",
                                    ifelse(pChi <= 0.05, "*", ""))),
         annotation = ifelse(chiSig == F & simSig == T, "Sim *", annotation),
         annotation = ifelse(chiSig == T & simSig == F, "Chi DNM Sim", annotation))%>%
  select(Isolate, pChi, chiSig, pSim, SEpSim, simSig, simsMatch, annotation)%>%
  distinct()

write.csv(stats, "./CoCulture_Data/coculture_stats_new.csv")
```

### Calculating Area Under Growth Curve to Determine Growth Effects
In this section, the area under the curve (AUC) of each growth curve is calculated, and one-tailed t-tests are conducted to determine the significance and directionality of differences in mean growth curve between xenic samples and axenic controls. We can then draw conclusions regarding both the significance of deviation in growth based on the linear regression tests above and effect of this deviation on algal growth based on the t-test data in this section.

```{r AUC calculations}
data_split4auc <- split(data, data$exact_isolate)

aucData <- foreach(i = 1:length(data_split4auc), .packages = c("DescTools", "tidyverse"), .combine = "rbind") %dopar% {
  df <- data_split4auc[[i]]
  AUC <- AUC(x = df$read_timeHours,
             y = df$ChlA_100, method = "spline")
  output <- data.frame("exact_isolate" = df$exact_isolate,
                       "Isolate" = df$Isolate,
                       "plate_no" = df$plate_no,
                       "host_species" = df$host_species,
                       "AUC" = AUC)%>% distinct()
  return(output)
}

AC_aucData <- aucData %>% filter(Isolate == "AC")

aucData_split <- aucData %>% filter(str_detect(.$Isolate, "^[:digit:]")) %>%
  split(., .$Isolate)

tTest_results <- foreach(i = 1:length(aucData_split), .packages = c("tidyverse", "broom"), .combine = "rbind") %dopar% {
  df <- aucData_split[[i]]
  host <- unique(df$host_species)
  plate <- unique(df$plate_no)
  Isolate <- unique(df$Isolate)
  ac_df <- AC_aucData %>% filter(host_species == host & plate_no == plate)
  stat_greater <- tidy(t.test(df$AUC, ac_df$AUC, alternative = "greater"))%>%
    mutate(pGreater = p.value, Isolate = Isolate)%>%
    select(Isolate, pGreater)
  stat_less <- tidy(t.test(df$AUC, ac_df$AUC, alternative = "less"))%>%
    mutate(pLess = p.value, Isolate = Isolate)%>% 
    select(Isolate, pLess)
  stats <- full_join(stat_greater, stat_less)
  return(stats)
}

stats_streamlined <- left_join(stats, tTest_results)%>% 
  select(Isolate, pChi, pSim, SEpSim, pGreater, pLess, annotation)%>%
  mutate(Effect = ifelse(pGreater > 0.05 & pLess > 0.05 & pSim > 0.05, "Not Significant",
                         ifelse(pGreater > 0.05 & pLess > 0.05 & pSim <= 0.05, "No Change to AUC",
                                ifelse(pGreater <= 0.05, "Positive",
                                       ifelse(pLess <= 0.05, "Negative",
                                              ifelse(pGreater <= 0.05 & pLess <= 0.05, "Error", NA))))))

write.csv(stats_streamlined, "./CoCulture_Data/coculture_stats_effects.csv")

relevant4_figs <- stats_streamlined %>% select(Isolate, annotation, Effect)
```

### Comparing Initial LRT and Refined P-Values
This plot shows the total number of samples for which the initial LRT-derived p-value and the refined p-value conflict over the significance of a given result. Usually, this manifests with a significant refined p-value and an insignificant intial P-value. If a sample is observed to have a significant LRT-derived p-value and an insignificant refined p-value, this sample likely requires further investigation.
```{r Check Statistics Plot}
chi_sim_compare <-  stats %>%
  filter(simsMatch == F)%>%
  mutate(compareSig = ifelse(chiSig == T & simSig == F, "Chi Significant\nSim Not", 
                              ifelse(chiSig == F & simSig == T, "Sim Significant\nChi not", "other")))%>%
  ggplot(., aes(x = compareSig, fill = compareSig))+
  geom_bar(stat = "count")

chi_sim_compare
```

### Plot Generation
This section applies the plotting functions outlined above to the data, and generates plots with statistics annotations for all samples.
```{r Plot Generation}
figData <- left_join(sampleData, relevant4_figs)

sample_list <- as.list(unique(figData$Isolate))

lapply(sample_list, dot_plot_isolates)


dataMean <- data %>%
  mutate(plate_no = as.numeric(plate_no))%>%
  group_by(plate_no, Isolate, host_species, read_time, read_day, read_timeHours)%>%
  summarize(ChlA_100_mean = mean(ChlA_100),
            ChlA_100_sd = sd(ChlA_100), .groups = "drop") %>%
  left_join(., relevant4_figs)
# %>% filter(Outlier == FALSE)

# lapply(sample_list, mean_plot_isolates)
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
